{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L14qs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kilKsIChiW0G"
      },
      "source": [
        "We showed that the VGG-16 network can be used to encode images it was not trained on---a cheese grater and a foot file---as vectors that are perfectly recognized by K nearest neighbors. What do you think would happen if we used nearest neighbors (or naive Bayes or a neural network) classifier on the raw vectors?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0wL-7mKuLue"
      },
      "source": [
        "We'll download addtional images from GitHub below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XdXSJxHvOBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b154204-e8dd-48f9-b808-8fc3cc24fe40"
      },
      "source": [
        "!wget https://github.com/mlittmancs/great_courses_ml/raw/master/imgs/tools.zip\n",
        "!unzip tools.zip"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-07 15:45:36--  https://github.com/mlittmancs/great_courses_ml/raw/master/imgs/tools.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/imgs/tools.zip [following]\n",
            "--2022-11-07 15:45:37--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/imgs/tools.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2502460 (2.4M) [application/zip]\n",
            "Saving to: ‘tools.zip.3’\n",
            "\n",
            "tools.zip.3         100%[===================>]   2.39M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-11-07 15:45:37 (37.8 MB/s) - ‘tools.zip.3’ saved [2502460/2502460]\n",
            "\n",
            "Archive:  tools.zip\n",
            "replace cg01.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: cg01.jpeg               \n",
            "  inflating: cg02.jpeg               \n",
            "  inflating: cg03.jpeg               \n",
            "  inflating: cg04.jpeg               \n",
            "  inflating: cg05.jpeg               \n",
            "  inflating: cg06.jpeg               \n",
            "  inflating: cg07.jpeg               \n",
            "  inflating: cg08.jpeg               \n",
            "  inflating: cg09.jpeg               \n",
            "  inflating: cg10.jpeg               \n",
            "  inflating: ff01.jpeg               \n",
            "  inflating: ff02.jpeg               \n",
            "  inflating: ff03.jpeg               \n",
            "  inflating: ff04.jpeg               \n",
            "  inflating: ff05.jpeg               \n",
            "  inflating: ff06.jpeg               \n",
            "  inflating: ff07.jpeg               \n",
            "  inflating: ff08.jpeg               \n",
            "  inflating: ff09.jpeg               \n",
            "  inflating: ff10.jpeg               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIvRfL5QaTrv"
      },
      "source": [
        "Loading the raw image vectors as a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ1GesmY9mDf"
      },
      "source": [
        "# get images\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from tensorflow import keras\n",
        "\n",
        "# from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "         \n",
        "dat = []\n",
        "labs = []\n",
        "imgs = []\n",
        "imgflist = [\"cg01\", \"cg02\", \"cg03\", \"cg04\", \"cg05\", \"cg06\", \"cg07\", \"cg08\", \"cg09\", \"cg10\",\n",
        "           \"ff01\", \"ff02\", \"ff03\", \"ff04\", \"ff05\", \"ff06\", \"ff07\", \"ff08\", \"ff09\", \"ff10\"]\n",
        "for imgf in imgflist:\n",
        "    img = keras.utils.load_img(imgf+\".jpeg\", target_size=(224,224))\n",
        "    imgs.append(img)\n",
        "    img_arr = np.expand_dims(keras.utils.img_to_array(img), axis=0)\n",
        "#    x = preprocess_input(img_arr)\n",
        "#    preds = model2.predict(x)\n",
        "    dat.append(img_arr.flatten())\n",
        "    labs.append(imgf[0:2] == 'ff')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj_J81yTbiwc"
      },
      "source": [
        "Dividing the data into training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4plqRVQrdWIQ"
      },
      "source": [
        "train = [i for i in range(0,5)]+[i for i in range(10,15)]\n",
        "test = [i for i in range(5,10)]+[i for i in range(15,20)]\n",
        "\n",
        "X_train = [dat[inst] for inst in train]\n",
        "y_train = [labs[inst] for inst in train]\n",
        "X_test =  [dat[inst] for inst in test]\n",
        "y_test =  [labs[inst] for inst in test]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL0qTNbHihsq"
      },
      "source": [
        "Train using Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_rkqAnbdcLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c013d5-e340-43f9-91be-3d9a18143523"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afJ7zkhrij1a"
      },
      "source": [
        "Train using nearest neighbor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD7MzdFcdiAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1dff9e-ceb3-4763-a3b6-29ff20ac15e1"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=1,metric=\"cosine\")\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa09vQuVimj8"
      },
      "source": [
        "Train using neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz95vOMDfN8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d641cc1-da11-44ab-8bd2-d04a6659a646"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=[100, 100, 100, 100, 100], max_iter = 10000)\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5fVZ_TlggDT"
      },
      "source": [
        "For comparison, here are those same algorithms using the representation that comes from VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9acgp2_ftSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eab4d8a-d941-47e9-d380-f6824da73178"
      },
      "source": [
        "!pip install keras=='2.3.1'\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.applications import vgg16\n",
        "from keras import backend as K\n",
        "\n",
        "model = vgg16.VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "model2 = Model(model.input, model.layers[-2].output)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.7/dist-packages (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (6.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.7.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIko-YKGiH-s"
      },
      "source": [
        "Gather the vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMdt2G2Agy-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca77a74-7f8c-49bd-ae82-1a09cb90f8aa"
      },
      "source": [
        "datraw = dat\n",
        "dat = []\n",
        "\n",
        "for img in imgs:\n",
        "    img_arr = np.expand_dims(keras.utils.img_to_array(img), axis=0)\n",
        "    x = preprocess_input(img_arr)\n",
        "    preds = model2.predict(x)\n",
        "    dat.append(preds[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7ff86d63d4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7ff86d63d4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 752ms/step\n",
            "1/1 [==============================] - 1s 804ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ3wimixiKY-"
      },
      "source": [
        "Make a new training/testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dgwO3Wwho1C"
      },
      "source": [
        "train = [i for i in range(0,5)]+[i for i in range(10,15)]\n",
        "test = [i for i in range(5,10)]+[i for i in range(15,20)]\n",
        "\n",
        "X_train = [dat[inst] for inst in train]\n",
        "y_train = [labs[inst] for inst in train]\n",
        "X_test =  [dat[inst] for inst in test]\n",
        "y_test =  [labs[inst] for inst in test]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes."
      ],
      "metadata": {
        "id": "ey2EuMUyw-i1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY3KmE9ThOZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ec5244-2ee9-4ae0-f858-ca7c36cf3a67"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9om5O0fYiPF8"
      },
      "source": [
        "Nearest neighbors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sO7EQGrhSdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ae756c-a844-41eb-e634-690a12aec81f"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=1,metric=\"cosine\")\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETy5W-4diRoB"
      },
      "source": [
        "And neural networks, all perfect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCysBL8HhUel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d76330-a4a6-49b8-8703-99ccdfaadd3f"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=[100, 100, 100, 100, 100], max_iter = 10000)\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    }
  ]
}